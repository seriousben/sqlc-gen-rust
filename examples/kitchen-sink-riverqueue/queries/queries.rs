/// This file is @generated by sqlc-gen-rust.
async fn pg_advisory_xact_lock(key: i64) -> Result<bool, Error> {
    let rec = sqlx::query!("
SELECT pg_advisory_xact_lock($1)
");
}
async fn pg_notify_many(topic: String, payload: Vec<String>) -> Result<bool, Error> {
    let rec = sqlx::query!(
        "
WITH topic_to_notify AS (
    SELECT
        concat(current_schema(), '.', $1::text) AS topic,
        unnest($2::text[]) AS payload
)
SELECT pg_notify(
    topic_to_notify.topic,
    topic_to_notify.payload
  )
FROM topic_to_notify
"
    );
}
#[derive(Debug, Clone)]
pub struct ClientCreateOrSetUpdatedAtInfo {
    id: String,
    metadata: serde_json::Value,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    updated_at: Option<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone)]
pub struct ClientCreateOrSetUpdatedAtRow {
    id: String,
    created_at: chrono::DateTime<chrono::Utc>,
    metadata: serde_json::Value,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    updated_at: chrono::DateTime<chrono::Utc>,
}
async fn client_create_or_set_updated_at(
    client_create_or_set_updated_at_info: ClientCreateOrSetUpdatedAtInfo,
) -> Result<ClientCreateOrSetUpdatedAtRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_client (
    id,
    metadata,
    paused_at,
    updated_at
) VALUES (
    $1,
    coalesce($2::jsonb, '{}'::jsonb),
    coalesce($3::timestamptz, NULL),
    coalesce($4::timestamptz, now())
) ON CONFLICT (name) DO UPDATE
SET
    updated_at = coalesce($4::timestamptz, now())
RETURNING id, created_at, metadata, paused_at, updated_at
"
    );
}
#[derive(Debug, Clone)]
pub struct ClientQueueCreateOrSetUpdatedAtManyInfo {
    metadata: serde_json::Value,
    name: Vec<String>,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    river_client_id: String,
    updated_at: Option<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone)]
pub struct ClientQueueCreateOrSetUpdatedAtManyRow {
    river_client_id: String,
    name: String,
    created_at: chrono::DateTime<chrono::Utc>,
    max_workers: i64,
    metadata: serde_json::Value,
    num_jobs_completed: i64,
    num_jobs_running: i64,
    updated_at: chrono::DateTime<chrono::Utc>,
}
async fn client_queue_create_or_set_updated_at_many(
    client_queue_create_or_set_updated_at_many_info: ClientQueueCreateOrSetUpdatedAtManyInfo,
) -> Result<ClientQueueCreateOrSetUpdatedAtManyRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_client_queue (
    metadata,
    name,
    paused_at,
    river_client_id,
    updated_at
) VALUES (
    coalesce($1::jsonb, '{}'),
    unnest($2::text[]),
    coalesce($3::timestamptz, NULL),
    $4,
    coalesce($5::timestamptz, now())
) ON CONFLICT (name) DO UPDATE
SET
    updated_at = coalesce($5::timestamptz, now())
RETURNING river_client_id, name, created_at, max_workers, metadata, num_jobs_completed, num_jobs_running, updated_at
"
    );
}
#[derive(Debug, Clone)]
pub struct JobCancelInfo {
    id: i64,
    control_topic: String,
    cancel_attempted_at: serde_json::Value,
}
#[derive(Debug, Clone)]
pub struct JobCancelRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_cancel(job_cancel_info: JobCancelInfo) -> Result<JobCancelRow, Error> {
    let rec = sqlx::query!(
        "
WITH locked_job AS (
    SELECT
        id, queue, state, finalized_at
    FROM river_job
    WHERE river_job.id = $1
    FOR UPDATE
),
notification AS (
    SELECT
        id,
        pg_notify(
            concat(current_schema(), '.', $2::text),
            json_build_object('action', 'cancel', 'job_id', id, 'queue', queue)::text
        )
    FROM
        locked_job
    WHERE
        state NOT IN ('cancelled', 'completed', 'discarded')
        AND finalized_at IS NULL
),
updated_job AS (
    UPDATE river_job
    SET
        -- If the job is actively running, we want to let its current client and
        -- producer handle the cancellation. Otherwise, immediately cancel it.
        state = CASE WHEN state = 'running' THEN state ELSE 'cancelled' END,
        finalized_at = CASE WHEN state = 'running' THEN finalized_at ELSE now() END,
        -- Mark the job as cancelled by query so that the rescuer knows not to
        -- rescue it, even if it gets stuck in the running state:
        metadata = jsonb_set(metadata, '{cancel_attempted_at}'::text[], $3::jsonb, true)
    FROM notification
    WHERE river_job.id = notification.id
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $1::bigint
    AND id NOT IN (SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
"
    );
}
async fn job_count_by_state(state: serde_json::Value) -> Result<bool, Error> {
    let rec = sqlx::query!("
SELECT count(*)
FROM river_job
WHERE state = $1
");
}
#[derive(Debug, Clone)]
pub struct JobDeleteRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_delete(id: i64) -> Result<JobDeleteRow, Error> {
    let rec = sqlx::query!(
        "
WITH job_to_delete AS (
    SELECT id
    FROM river_job
    WHERE river_job.id = $1
    FOR UPDATE
),
deleted_job AS (
    DELETE
    FROM river_job
    USING job_to_delete
    WHERE river_job.id = job_to_delete.id
        -- Do not touch running jobs:
        AND river_job.state != 'running'
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $1::bigint
    AND id NOT IN (SELECT id FROM deleted_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM deleted_job
"
    );
}
#[derive(Debug, Clone)]
pub struct JobDeleteBeforeInfo {
    cancelled_finalized_at_horizon: chrono::DateTime<chrono::Utc>,
    completed_finalized_at_horizon: chrono::DateTime<chrono::Utc>,
    discarded_finalized_at_horizon: chrono::DateTime<chrono::Utc>,
    max: i64,
}
async fn job_delete_before(
    job_delete_before_info: JobDeleteBeforeInfo,
) -> Result<bool, Error> {
    let rec = sqlx::query!(
        "
WITH deleted_jobs AS (
    DELETE FROM river_job
    WHERE id IN (
        SELECT id
        FROM river_job
        WHERE
            (state = 'cancelled' AND finalized_at < $1::timestamptz) OR
            (state = 'completed' AND finalized_at < $2::timestamptz) OR
            (state = 'discarded' AND finalized_at < $3::timestamptz)
        ORDER BY id
        LIMIT $4::bigint
    )
    RETURNING id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
)
SELECT count(*)
FROM deleted_jobs
"
    );
}
#[derive(Debug, Clone)]
pub struct JobGetAvailableInfo {
    attempted_by: String,
    queue: String,
    now: Option<chrono::DateTime<chrono::Utc>>,
    max: i32,
}
#[derive(Debug, Clone)]
pub struct JobGetAvailableRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_get_available(
    job_get_available_info: JobGetAvailableInfo,
) -> Result<Vec<JobGetAvailableRow>, Error> {
    let rec = sqlx::query!(
        "
WITH locked_jobs AS (
    SELECT
        id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
    FROM
        river_job
    WHERE
        state = 'available'
        AND queue = $2::text
        AND scheduled_at <= coalesce($3::timestamptz, now())
    ORDER BY
        priority ASC,
        scheduled_at ASC,
        id ASC
    LIMIT $4::integer
    FOR UPDATE
    SKIP LOCKED
)
UPDATE
    river_job
SET
    state = 'running',
    attempt = river_job.attempt + 1,
    attempted_at = now(),
    attempted_by = array_append(river_job.attempted_by, $1::text)
FROM
    locked_jobs
WHERE
    river_job.id = locked_jobs.id
RETURNING
    river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
"
    );
}
#[derive(Debug, Clone)]
pub struct JobGetByKindAndUniquePropertiesInfo {
    kind: String,
    by_args: bool,
    args: serde_json::Value,
    by_created_at: bool,
    created_at_begin: chrono::DateTime<chrono::Utc>,
    created_at_end: chrono::DateTime<chrono::Utc>,
    by_queue: bool,
    queue: String,
    by_state: bool,
    state: Vec<String>,
}
#[derive(Debug, Clone)]
pub struct JobGetByKindAndUniquePropertiesRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_get_by_kind_and_unique_properties(
    job_get_by_kind_and_unique_properties_info: JobGetByKindAndUniquePropertiesInfo,
) -> Result<JobGetByKindAndUniquePropertiesRow, Error> {
    let rec = sqlx::query!(
        "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE kind = $1
    AND CASE WHEN $2::boolean THEN args = $3 ELSE true END
    AND CASE WHEN $4::boolean THEN tstzrange($5::timestamptz, $6::timestamptz, '[)') @> created_at ELSE true END
    AND CASE WHEN $7::boolean THEN queue = $8 ELSE true END
    AND CASE WHEN $9::boolean THEN state::text = any($10::text[]) ELSE true END
"
    );
}
#[derive(Debug, Clone)]
pub struct JobGetByKindManyRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_get_by_kind_many(
    kind: Vec<String>,
) -> Result<Vec<JobGetByKindManyRow>, Error> {
    let rec = sqlx::query!(
        "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE kind = any($1::text[])
ORDER BY id
"
    );
}
#[derive(Debug, Clone)]
pub struct JobGetByIdRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_get_by_id(id: i64) -> Result<JobGetByIDRow, Error> {
    let rec = sqlx::query!(
        "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $1
LIMIT 1
"
    );
}
#[derive(Debug, Clone)]
pub struct JobGetByIdManyRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_get_by_id_many(id: Vec<i64>) -> Result<Vec<JobGetByIDManyRow>, Error> {
    let rec = sqlx::query!(
        "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = any($1::bigint[])
ORDER BY id
"
    );
}
#[derive(Debug, Clone)]
pub struct JobGetStuckRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_get_stuck(
    stuck_horizon: chrono::DateTime<chrono::Utc>,
    max: i32,
) -> Result<Vec<JobGetStuckRow>, Error> {
    let rec = sqlx::query!(
        "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE state = 'running'
    AND attempted_at < $1::timestamptz
ORDER BY id
LIMIT $2
"
    );
}
#[derive(Debug, Clone)]
pub struct JobInsertFastManyInfo {
    args: Vec<serde_json::Value>,
    kind: Vec<String>,
    max_attempts: Vec<i16>,
    metadata: Vec<serde_json::Value>,
    priority: Vec<i16>,
    queue: Vec<String>,
    scheduled_at: Vec<chrono::DateTime<chrono::Utc>>,
    state: Vec<String>,
    tags: Vec<String>,
    unique_key: Vec<u8>,
    unique_states: Vec<serde_json::Value>,
}
#[derive(Debug, Clone)]
pub struct JobInsertFastManyRow {
    river_job: Option<serde_json::Value>,
    unique_skipped_as_duplicate: bool,
}
async fn job_insert_fast_many(
    job_insert_fast_many_info: JobInsertFastManyInfo,
) -> Result<Vec<JobInsertFastManyRow>, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_job(
    args,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key,
    unique_states
) SELECT
    unnest($1::jsonb[]),
    unnest($2::text[]),
    unnest($3::smallint[]),
    unnest($4::jsonb[]),
    unnest($5::smallint[]),
    unnest($6::text[]),
    unnest($7::timestamptz[]),
    -- To avoid requiring pgx users to register the OID of the river_job_state[]
    -- type, we cast the array to text[] and then to river_job_state.
    unnest($8::text[])::river_job_state,
    -- Unnest on a multi-dimensional array will fully flatten the array, so we
    -- encode the tag list as a comma-separated string and split it in the
    -- query.
    string_to_array(unnest($9::text[]), ','),

    unnest($10::bytea[]),
    unnest($11::bit(8)[])

ON CONFLICT (unique_key)
    WHERE unique_key IS NOT NULL
      AND unique_states IS NOT NULL
      AND river_job_state_in_bitmask(unique_states, state)
    -- Something needs to be updated for a row to be returned on a conflict.
    DO UPDATE SET kind = EXCLUDED.kind
RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states, (xmax != 0) AS unique_skipped_as_duplicate
"
    );
}
#[derive(Debug, Clone)]
pub struct JobInsertFastManyNoReturningInfo {
    args: Vec<serde_json::Value>,
    kind: Vec<String>,
    max_attempts: Vec<i16>,
    metadata: Vec<serde_json::Value>,
    priority: Vec<i16>,
    queue: Vec<String>,
    scheduled_at: Vec<chrono::DateTime<chrono::Utc>>,
    state: Vec<serde_json::Value>,
    tags: Vec<String>,
    unique_key: Vec<u8>,
    unique_states: Vec<serde_json::Value>,
}
#[derive(Debug, Clone)]
pub struct JobInsertFastManyNoReturningRow {}
async fn job_insert_fast_many_no_returning(
    job_insert_fast_many_no_returning_info: JobInsertFastManyNoReturningInfo,
) -> Result<JobInsertFastManyNoReturningRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_job(
    args,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key,
    unique_states
) SELECT
    unnest($1::jsonb[]),
    unnest($2::text[]),
    unnest($3::smallint[]),
    unnest($4::jsonb[]),
    unnest($5::smallint[]),
    unnest($6::text[]),
    unnest($7::timestamptz[]),
    unnest($8::river_job_state[]),

    -- lib/pq really, REALLY does not play nicely with multi-dimensional arrays,
    -- so instead we pack each set of tags into a string, send them through,
    -- then unpack them here into an array to put in each row. This isn't
    -- necessary in the Pgx driver where copyfrom is used instead.
    string_to_array(unnest($9::text[]), ','),

    unnest($10::bytea[]),
    unnest($11::bit(8)[])

ON CONFLICT (unique_key)
    WHERE unique_key IS NOT NULL
      AND unique_states IS NOT NULL
      AND river_job_state_in_bitmask(unique_states, state)
DO NOTHING
"
    );
}
#[derive(Debug, Clone)]
pub struct JobInsertFullInfo {
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    created_at: Option<chrono::DateTime<chrono::Utc>>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    scheduled_at: Option<chrono::DateTime<chrono::Utc>>,
    state: serde_json::Value,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
#[derive(Debug, Clone)]
pub struct JobInsertFullRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_insert_full(
    job_insert_full_info: JobInsertFullInfo,
) -> Result<JobInsertFullRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_job(
    args,
    attempt,
    attempted_at,
    created_at,
    errors,
    finalized_at,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key,
    unique_states
) VALUES (
    $1::jsonb,
    coalesce($2::smallint, 0),
    $3,
    coalesce($4::timestamptz, now()),
    $5,
    $6,
    $7,
    $8::smallint,
    coalesce($9::jsonb, '{}'),
    $10,
    $11,
    coalesce($12::timestamptz, now()),
    $13,
    coalesce($14::varchar(255)[], '{}'),
    $15,
    $16
) RETURNING id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
"
    );
}
#[derive(Debug, Clone)]
pub struct JobRescueManyInfo {
    id: Vec<i64>,
    error: Vec<serde_json::Value>,
    finalized_at: Vec<chrono::DateTime<chrono::Utc>>,
    scheduled_at: Vec<chrono::DateTime<chrono::Utc>>,
    state: Vec<String>,
}
#[derive(Debug, Clone)]
pub struct JobRescueManyRow {}
async fn job_rescue_many(
    job_rescue_many_info: JobRescueManyInfo,
) -> Result<JobRescueManyRow, Error> {
    let rec = sqlx::query!(
        "
UPDATE river_job
SET
    errors = array_append(errors, updated_job.error),
    finalized_at = updated_job.finalized_at,
    scheduled_at = updated_job.scheduled_at,
    state = updated_job.state
FROM (
    SELECT
        unnest($1::bigint[]) AS id,
        unnest($2::jsonb[]) AS error,
        nullif(unnest($3::timestamptz[]), '0001-01-01 00:00:00 +0000') AS finalized_at,
        unnest($4::timestamptz[]) AS scheduled_at,
        unnest($5::text[])::river_job_state AS state
) AS updated_job
WHERE river_job.id = updated_job.id
"
    );
}
#[derive(Debug, Clone)]
pub struct JobRetryRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_retry(id: i64) -> Result<JobRetryRow, Error> {
    let rec = sqlx::query!(
        "
WITH job_to_update AS (
    SELECT id
    FROM river_job
    WHERE river_job.id = $1
    FOR UPDATE
),
updated_job AS (
    UPDATE river_job
    SET
        state = 'available',
        scheduled_at = now(),
        max_attempts = CASE WHEN attempt = max_attempts THEN max_attempts + 1 ELSE max_attempts END,
        finalized_at = NULL
    FROM job_to_update
    WHERE river_job.id = job_to_update.id
        -- Do not touch running jobs:
        AND river_job.state != 'running'
        -- If the job is already available with a prior scheduled_at, leave it alone.
        AND NOT (river_job.state = 'available' AND river_job.scheduled_at < now())
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $1::bigint
    AND id NOT IN (SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
"
    );
}
#[derive(Debug, Clone)]
pub struct JobScheduleRow {
    river_job: Option<serde_json::Value>,
    conflict_discarded: bool,
}
async fn job_schedule(
    now: chrono::DateTime<chrono::Utc>,
    max: i64,
) -> Result<Vec<JobScheduleRow>, Error> {
    let rec = sqlx::query!(
        "
WITH jobs_to_schedule AS (
    SELECT
        id,
        unique_key,
        unique_states,
        priority,
        scheduled_at
    FROM river_job
    WHERE
        state IN ('retryable', 'scheduled')
        AND queue IS NOT NULL
        AND priority >= 0
        AND scheduled_at <= $1::timestamptz
    ORDER BY
        priority,
        scheduled_at,
        id
    LIMIT $2::bigint
    FOR UPDATE
),
jobs_with_rownum AS (
    SELECT
        id, unique_key, unique_states, priority, scheduled_at,
        CASE
            WHEN unique_key IS NOT NULL AND unique_states IS NOT NULL THEN
                ROW_NUMBER() OVER (
                    PARTITION BY unique_key
                    ORDER BY priority, scheduled_at, id
                )
            ELSE NULL
        END AS row_num
    FROM jobs_to_schedule
),
unique_conflicts AS (
    SELECT river_job.unique_key
    FROM river_job
    JOIN jobs_with_rownum
        ON river_job.unique_key = jobs_with_rownum.unique_key
        AND river_job.id != jobs_with_rownum.id
    WHERE
        river_job.unique_key IS NOT NULL
        AND river_job.unique_states IS NOT NULL
        AND river_job_state_in_bitmask(river_job.unique_states, river_job.state)
),
job_updates AS (
    SELECT
        job.id,
        job.unique_key,
        job.unique_states,
        CASE
            WHEN job.row_num IS NULL THEN 'available'::river_job_state
            WHEN uc.unique_key IS NOT NULL THEN 'discarded'::river_job_state
            WHEN job.row_num = 1 THEN 'available'::river_job_state
            ELSE 'discarded'::river_job_state
        END AS new_state,
        (job.row_num IS NOT NULL AND (uc.unique_key IS NOT NULL OR job.row_num > 1)) AS finalized_at_do_update,
        (job.row_num IS NOT NULL AND (uc.unique_key IS NOT NULL OR job.row_num > 1)) AS metadata_do_update
    FROM jobs_with_rownum job
    LEFT JOIN unique_conflicts uc ON job.unique_key = uc.unique_key
),
updated_jobs AS (
    UPDATE river_job
    SET
        state        = job_updates.new_state,
        finalized_at = CASE WHEN job_updates.finalized_at_do_update THEN $1::timestamptz
                            ELSE river_job.finalized_at END,
        metadata     = CASE WHEN job_updates.metadata_do_update THEN river_job.metadata || '{\"unique_key_conflict\": \"scheduler_discarded\"}'::jsonb
                            ELSE river_job.metadata END
    FROM job_updates
    WHERE river_job.id = job_updates.id
    RETURNING
        river_job.id,
        job_updates.new_state = 'discarded'::river_job_state AS conflict_discarded
)
SELECT
    river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states,
    updated_jobs.conflict_discarded
FROM river_job
JOIN updated_jobs ON river_job.id = updated_jobs.id
"
    );
}
#[derive(Debug, Clone)]
pub struct JobSetCompleteIfRunningManyRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_set_complete_if_running_many(
    id: Vec<i64>,
    finalized_at: Vec<chrono::DateTime<chrono::Utc>>,
) -> Result<Vec<JobSetCompleteIfRunningManyRow>, Error> {
    let rec = sqlx::query!(
        "
WITH job_to_finalized_at AS (
    SELECT
        unnest($1::bigint[]) AS id,
        unnest($2::timestamptz[]) AS finalized_at
),
job_to_update AS (
    SELECT river_job.id, job_to_finalized_at.finalized_at
    FROM river_job, job_to_finalized_at
    WHERE river_job.id = job_to_finalized_at.id
        AND river_job.state = 'running'
    FOR UPDATE
),
updated_job AS (
    UPDATE river_job
    SET
        finalized_at = job_to_update.finalized_at,
        state = 'completed'
    FROM job_to_update
    WHERE river_job.id = job_to_update.id
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id IN (SELECT id FROM job_to_finalized_at EXCEPT SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
"
    );
}
#[derive(Debug, Clone)]
pub struct JobSetStateIfRunningInfo {
    state: serde_json::Value,
    id: i64,
    finalized_at_do_update: bool,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    error_do_update: bool,
    error: serde_json::Value,
    max_attempts_update: bool,
    max_attempts: i16,
    scheduled_at_do_update: bool,
    scheduled_at: Option<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone)]
pub struct JobSetStateIfRunningRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_set_state_if_running(
    job_set_state_if_running_info: JobSetStateIfRunningInfo,
) -> Result<JobSetStateIfRunningRow, Error> {
    let rec = sqlx::query!(
        "
WITH job_to_update AS (
    SELECT
        id,
        $1::river_job_state IN ('retryable', 'scheduled') AND metadata ? 'cancel_attempted_at' AS should_cancel
    FROM river_job
    WHERE id = $2::bigint
    FOR UPDATE
),
updated_job AS (
    UPDATE river_job
    SET
        state        = CASE WHEN should_cancel                                           THEN 'cancelled'::river_job_state
                            ELSE $1::river_job_state END,
        finalized_at = CASE WHEN should_cancel                                           THEN now()
                            WHEN $3::boolean                        THEN $4
                            ELSE finalized_at END,
        errors       = CASE WHEN $5::boolean                               THEN array_append(errors, $6::jsonb)
                            ELSE errors       END,
        max_attempts = CASE WHEN NOT should_cancel AND $7::boolean     THEN $8
                            ELSE max_attempts END,
        scheduled_at = CASE WHEN NOT should_cancel AND $9::boolean  THEN $10::timestamptz
                            ELSE scheduled_at END
    FROM job_to_update
    WHERE river_job.id = job_to_update.id
        AND river_job.state = 'running'
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $2::bigint
    AND id NOT IN (SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
"
    );
}
#[derive(Debug, Clone)]
pub struct JobSetStateIfRunningManyInfo {
    ids: Vec<i64>,
    state: Vec<String>,
    finalized_at_do_update: Vec<bool>,
    finalized_at: Vec<chrono::DateTime<chrono::Utc>>,
    errors_do_update: Vec<bool>,
    errors: Vec<serde_json::Value>,
    max_attempts_do_update: Vec<bool>,
    max_attempts: Vec<i32>,
    scheduled_at_do_update: Vec<bool>,
    scheduled_at: Vec<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone)]
pub struct JobSetStateIfRunningManyRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_set_state_if_running_many(
    job_set_state_if_running_many_info: JobSetStateIfRunningManyInfo,
) -> Result<Vec<JobSetStateIfRunningManyRow>, Error> {
    let rec = sqlx::query!(
        "
WITH job_input AS (
    SELECT
        unnest($1::bigint[]) AS id,
        -- To avoid requiring pgx users to register the OID of the river_job_state[]
        -- type, we cast the array to text[] and then to river_job_state.
        unnest($2::text[])::river_job_state AS state,
        unnest($3::boolean[]) AS finalized_at_do_update,
        unnest($4::timestamptz[]) AS finalized_at,
        unnest($5::boolean[]) AS errors_do_update,
        unnest($6::jsonb[]) AS errors,
        unnest($7::boolean[]) AS max_attempts_do_update,
        unnest($8::int[]) AS max_attempts,
        unnest($9::boolean[]) AS scheduled_at_do_update,
        unnest($10::timestamptz[]) AS scheduled_at
),
job_to_update AS (
    SELECT
        river_job.id,
        job_input.state,
        job_input.finalized_at,
        job_input.errors,
        job_input.max_attempts,
        job_input.scheduled_at,
        (job_input.state IN ('retryable', 'scheduled') AND river_job.metadata ? 'cancel_attempted_at') AS should_cancel,
        job_input.finalized_at_do_update,
        job_input.errors_do_update,
        job_input.max_attempts_do_update,
        job_input.scheduled_at_do_update
    FROM river_job
    JOIN job_input ON river_job.id = job_input.id
    WHERE river_job.state = 'running'
    FOR UPDATE
),
updated_job AS (
    UPDATE river_job
    SET
        state        = CASE WHEN job_to_update.should_cancel THEN 'cancelled'::river_job_state
                            ELSE job_to_update.state END,
        finalized_at = CASE WHEN job_to_update.should_cancel THEN now()
                            WHEN job_to_update.finalized_at_do_update THEN job_to_update.finalized_at
                            ELSE river_job.finalized_at END,
        errors       = CASE WHEN job_to_update.errors_do_update THEN array_append(river_job.errors, job_to_update.errors)
                            ELSE river_job.errors END,
        max_attempts = CASE WHEN NOT job_to_update.should_cancel AND job_to_update.max_attempts_do_update THEN job_to_update.max_attempts
                            ELSE river_job.max_attempts END,
        scheduled_at = CASE WHEN NOT job_to_update.should_cancel AND job_to_update.scheduled_at_do_update THEN job_to_update.scheduled_at
                            ELSE river_job.scheduled_at END
    FROM job_to_update
    WHERE river_job.id = job_to_update.id
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id IN (SELECT id FROM job_input)
  AND id NOT IN (SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
"
    );
}
#[derive(Debug, Clone)]
pub struct JobUpdateInfo {
    attempt_do_update: bool,
    attempt: i16,
    attempted_at_do_update: bool,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    errors_do_update: bool,
    errors: Vec<serde_json::Value>,
    finalized_at_do_update: bool,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    state_do_update: bool,
    state: serde_json::Value,
    id: i64,
}
#[derive(Debug, Clone)]
pub struct JobUpdateRow {
    id: i64,
    args: serde_json::Value,
    attempt: i16,
    attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    attempted_by: Option<Vec<String>>,
    created_at: chrono::DateTime<chrono::Utc>,
    errors: Option<Vec<serde_json::Value>>,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    state: serde_json::Value,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    tags: Vec<serde_json::Value>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
async fn job_update(job_update_info: JobUpdateInfo) -> Result<JobUpdateRow, Error> {
    let rec = sqlx::query!(
        "
UPDATE river_job
SET
    attempt = CASE WHEN $1::boolean THEN $2 ELSE attempt END,
    attempted_at = CASE WHEN $3::boolean THEN $4 ELSE attempted_at END,
    errors = CASE WHEN $5::boolean THEN $6::jsonb[] ELSE errors END,
    finalized_at = CASE WHEN $7::boolean THEN $8 ELSE finalized_at END,
    state = CASE WHEN $9::boolean THEN $10 ELSE state END
WHERE id = $11
RETURNING id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
"
    );
}
#[derive(Debug, Clone)]
pub struct JobInsertFastManyCopyFromInfo {
    args: serde_json::Value,
    finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    kind: String,
    max_attempts: i16,
    metadata: serde_json::Value,
    priority: i16,
    queue: String,
    scheduled_at: chrono::DateTime<chrono::Utc>,
    state: serde_json::Value,
    tags: Vec<String>,
    unique_key: Option<u8>,
    unique_states: Option<serde_json::Value>,
}
#[derive(Debug, Clone)]
pub struct JobInsertFastManyCopyFromRow {}
async fn job_insert_fast_many_copy_from(
    job_insert_fast_many_copy_from_info: JobInsertFastManyCopyFromInfo,
) -> Result<JobInsertFastManyCopyFromRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_job(
    args,
    finalized_at,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key,
    unique_states
) VALUES (
    $1,
    $2,
    $3,
    $4,
    $5,
    $6,
    $7,
    $8,
    $9,
    $10,
    $11,
    $12
)
"
    );
}
#[derive(Debug, Clone)]
pub struct LeaderAttemptElectRow {}
async fn leader_attempt_elect(
    leader_id: String,
    ttl: chrono::Duration,
) -> Result<LeaderAttemptElectRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_leader(leader_id, elected_at, expires_at)
    VALUES ($1, now(), now() + $2::interval)
ON CONFLICT (name)
    DO NOTHING
"
    );
}
#[derive(Debug, Clone)]
pub struct LeaderAttemptReelectRow {}
async fn leader_attempt_reelect(
    leader_id: String,
    ttl: chrono::Duration,
) -> Result<LeaderAttemptReelectRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_leader(leader_id, elected_at, expires_at)
    VALUES ($1, now(), now() + $2::interval)
ON CONFLICT (name)
    DO UPDATE SET
        expires_at = now() + $2
    WHERE
        river_leader.leader_id = $1
"
    );
}
#[derive(Debug, Clone)]
pub struct LeaderDeleteExpiredRow {}
async fn leader_delete_expired() -> Result<LeaderDeleteExpiredRow, Error> {
    let rec = sqlx::query!("
DELETE FROM river_leader
WHERE expires_at < now()
");
}
#[derive(Debug, Clone)]
pub struct LeaderGetElectedLeaderRow {
    elected_at: chrono::DateTime<chrono::Utc>,
    expires_at: chrono::DateTime<chrono::Utc>,
    leader_id: String,
    name: String,
}
async fn leader_get_elected_leader() -> Result<LeaderGetElectedLeaderRow, Error> {
    let rec = sqlx::query!(
        "
SELECT elected_at, expires_at, leader_id, name
FROM river_leader
"
    );
}
#[derive(Debug, Clone)]
pub struct LeaderInsertInfo {
    elected_at: Option<chrono::DateTime<chrono::Utc>>,
    expires_at: Option<chrono::DateTime<chrono::Utc>>,
    ttl: chrono::Duration,
    leader_id: String,
}
#[derive(Debug, Clone)]
pub struct LeaderInsertRow {
    elected_at: chrono::DateTime<chrono::Utc>,
    expires_at: chrono::DateTime<chrono::Utc>,
    leader_id: String,
    name: String,
}
async fn leader_insert(
    leader_insert_info: LeaderInsertInfo,
) -> Result<LeaderInsertRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_leader(
    elected_at,
    expires_at,
    leader_id
) VALUES (
    coalesce($1::timestamptz, now()),
    coalesce($2::timestamptz, now() + $3::interval),
    $4
) RETURNING elected_at, expires_at, leader_id, name
"
    );
}
#[derive(Debug, Clone)]
pub struct LeaderResignRow {}
async fn leader_resign(
    leader_id: String,
    leadership_topic: String,
) -> Result<LeaderResignRow, Error> {
    let rec = sqlx::query!(
        "
WITH currently_held_leaders AS (
  SELECT elected_at, expires_at, leader_id, name
  FROM river_leader
  WHERE leader_id = $1::text
  FOR UPDATE
),
notified_resignations AS (
    SELECT pg_notify(
        concat(current_schema(), '.', $2::text),
        json_build_object('leader_id', leader_id, 'action', 'resigned')::text
    )
    FROM currently_held_leaders
)
DELETE FROM river_leader USING notified_resignations
"
    );
}
#[derive(Debug, Clone)]
pub struct RiverMigrationDeleteAssumingMainManyRow {
    created_at: chrono::DateTime<chrono::Utc>,
    version: i64,
}
async fn river_migration_delete_assuming_main_many(
    version: Vec<i64>,
) -> Result<Vec<RiverMigrationDeleteAssumingMainManyRow>, Error> {
    let rec = sqlx::query!(
        "
DELETE FROM river_migration
WHERE version = any($1::bigint[])
RETURNING
    created_at,
    version
"
    );
}
#[derive(Debug, Clone)]
pub struct RiverMigrationDeleteByLineAndVersionManyRow {
    line: String,
    version: i64,
    created_at: chrono::DateTime<chrono::Utc>,
}
async fn river_migration_delete_by_line_and_version_many(
    line: String,
    version: Vec<i64>,
) -> Result<Vec<RiverMigrationDeleteByLineAndVersionManyRow>, Error> {
    let rec = sqlx::query!(
        "
DELETE FROM river_migration
WHERE line = $1
    AND version = any($2::bigint[])
RETURNING line, version, created_at
"
    );
}
#[derive(Debug, Clone)]
pub struct RiverMigrationGetAllAssumingMainRow {
    created_at: chrono::DateTime<chrono::Utc>,
    version: i64,
}
async fn river_migration_get_all_assuming_main() -> Result<
    Vec<RiverMigrationGetAllAssumingMainRow>,
    Error,
> {
    let rec = sqlx::query!(
        "
SELECT
    created_at,
    version
FROM river_migration
ORDER BY version
"
    );
}
#[derive(Debug, Clone)]
pub struct RiverMigrationGetByLineRow {
    line: String,
    version: i64,
    created_at: chrono::DateTime<chrono::Utc>,
}
async fn river_migration_get_by_line(
    line: String,
) -> Result<Vec<RiverMigrationGetByLineRow>, Error> {
    let rec = sqlx::query!(
        "
SELECT line, version, created_at
FROM river_migration
WHERE line = $1
ORDER BY version
"
    );
}
#[derive(Debug, Clone)]
pub struct RiverMigrationInsertRow {
    line: String,
    version: i64,
    created_at: chrono::DateTime<chrono::Utc>,
}
async fn river_migration_insert(
    line: String,
    version: i64,
) -> Result<RiverMigrationInsertRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_migration (
    line,
    version
) VALUES (
    $1,
    $2
) RETURNING line, version, created_at
"
    );
}
#[derive(Debug, Clone)]
pub struct RiverMigrationInsertManyRow {
    line: String,
    version: i64,
    created_at: chrono::DateTime<chrono::Utc>,
}
async fn river_migration_insert_many(
    line: String,
    version: Vec<i64>,
) -> Result<Vec<RiverMigrationInsertManyRow>, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_migration (
    line,
    version
)
SELECT
    $1,
    unnest($2::bigint[])
RETURNING line, version, created_at
"
    );
}
#[derive(Debug, Clone)]
pub struct RiverMigrationInsertManyAssumingMainRow {
    created_at: chrono::DateTime<chrono::Utc>,
    version: i64,
}
async fn river_migration_insert_many_assuming_main(
    version: Vec<i64>,
) -> Result<Vec<RiverMigrationInsertManyAssumingMainRow>, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_migration (
    version
)
SELECT
    unnest($1::bigint[])
RETURNING
    created_at,
    version
"
    );
}
async fn column_exists(table_name: String, column_name: String) -> Result<bool, Error> {
    let rec = sqlx::query!(
        "
SELECT EXISTS (
    SELECT column_name
    FROM information_schema.columns 
    WHERE table_name = $1::text
        AND table_schema = CURRENT_SCHEMA
        AND column_name = $2::text
)
"
    );
}
async fn table_exists(table_name: String) -> Result<bool, Error> {
    let rec = sqlx::query!(
        "
SELECT CASE WHEN to_regclass($1) IS NULL THEN false
            ELSE true END
"
    );
}
#[derive(Debug, Clone)]
pub struct QueueCreateOrSetUpdatedAtInfo {
    metadata: serde_json::Value,
    name: String,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    updated_at: Option<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone)]
pub struct QueueCreateOrSetUpdatedAtRow {
    name: String,
    created_at: chrono::DateTime<chrono::Utc>,
    metadata: serde_json::Value,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    updated_at: chrono::DateTime<chrono::Utc>,
}
async fn queue_create_or_set_updated_at(
    queue_create_or_set_updated_at_info: QueueCreateOrSetUpdatedAtInfo,
) -> Result<QueueCreateOrSetUpdatedAtRow, Error> {
    let rec = sqlx::query!(
        "
INSERT INTO river_queue(
    created_at,
    metadata,
    name,
    paused_at,
    updated_at
) VALUES (
    now(),
    coalesce($1::jsonb, '{}'::jsonb),
    $2::text,
    coalesce($3::timestamptz, NULL),
    coalesce($4::timestamptz, now())
) ON CONFLICT (name) DO UPDATE
SET
    updated_at = coalesce($4::timestamptz, now())
RETURNING name, created_at, metadata, paused_at, updated_at
"
    );
}
#[derive(Debug, Clone)]
pub struct QueueDeleteExpiredRow {
    name: String,
    created_at: chrono::DateTime<chrono::Utc>,
    metadata: serde_json::Value,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    updated_at: chrono::DateTime<chrono::Utc>,
}
async fn queue_delete_expired(
    updated_at_horizon: chrono::DateTime<chrono::Utc>,
    max: i64,
) -> Result<Vec<QueueDeleteExpiredRow>, Error> {
    let rec = sqlx::query!(
        "
DELETE FROM river_queue
WHERE name IN (
    SELECT name
    FROM river_queue
    WHERE updated_at < $1::timestamptz
    ORDER BY name ASC
    LIMIT $2::bigint
)
RETURNING name, created_at, metadata, paused_at, updated_at
"
    );
}
#[derive(Debug, Clone)]
pub struct QueueGetRow {
    name: String,
    created_at: chrono::DateTime<chrono::Utc>,
    metadata: serde_json::Value,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    updated_at: chrono::DateTime<chrono::Utc>,
}
async fn queue_get(name: String) -> Result<QueueGetRow, Error> {
    let rec = sqlx::query!(
        "
SELECT name, created_at, metadata, paused_at, updated_at
FROM river_queue
WHERE name = $1::text
"
    );
}
#[derive(Debug, Clone)]
pub struct QueueListRow {
    name: String,
    created_at: chrono::DateTime<chrono::Utc>,
    metadata: serde_json::Value,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    updated_at: chrono::DateTime<chrono::Utc>,
}
async fn queue_list(limit_count: i32) -> Result<Vec<QueueListRow>, Error> {
    let rec = sqlx::query!(
        "
SELECT name, created_at, metadata, paused_at, updated_at
FROM river_queue
ORDER BY name ASC
LIMIT $1::integer
"
    );
}
#[derive(Debug, Clone)]
pub struct QueuePauseRow {
    name: String,
    created_at: chrono::DateTime<chrono::Utc>,
    metadata: serde_json::Value,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    updated_at: chrono::DateTime<chrono::Utc>,
}
async fn queue_pause(name: String) -> Result<QueuePauseRow, Error> {
    let rec = sqlx::query!(
        "
WITH queue_to_update AS (
    SELECT name, paused_at
    FROM river_queue
    WHERE CASE WHEN $1::text = '*' THEN true ELSE name = $1 END
    FOR UPDATE
),
updated_queue AS (
    UPDATE river_queue
    SET
        paused_at = now(),
        updated_at = now()
    FROM queue_to_update
    WHERE river_queue.name = queue_to_update.name
        AND river_queue.paused_at IS NULL
    RETURNING river_queue.name, river_queue.created_at, river_queue.metadata, river_queue.paused_at, river_queue.updated_at
)
SELECT name, created_at, metadata, paused_at, updated_at
FROM river_queue
WHERE name = $1
    AND name NOT IN (SELECT name FROM updated_queue)
UNION
SELECT name, created_at, metadata, paused_at, updated_at
FROM updated_queue
"
    );
}
#[derive(Debug, Clone)]
pub struct QueueResumeRow {
    name: String,
    created_at: chrono::DateTime<chrono::Utc>,
    metadata: serde_json::Value,
    paused_at: Option<chrono::DateTime<chrono::Utc>>,
    updated_at: chrono::DateTime<chrono::Utc>,
}
async fn queue_resume(name: String) -> Result<QueueResumeRow, Error> {
    let rec = sqlx::query!(
        "
WITH queue_to_update AS (
    SELECT name
    FROM river_queue
    WHERE CASE WHEN $1::text = '*' THEN true ELSE river_queue.name = $1::text END
    FOR UPDATE
),
updated_queue AS (
    UPDATE river_queue
    SET
        paused_at = NULL,
        updated_at = now()
    FROM queue_to_update
    WHERE river_queue.name = queue_to_update.name
    RETURNING river_queue.name, river_queue.created_at, river_queue.metadata, river_queue.paused_at, river_queue.updated_at
)
SELECT name, created_at, metadata, paused_at, updated_at
FROM river_queue
WHERE name = $1
    AND name NOT IN (SELECT name FROM updated_queue)
UNION
SELECT name, created_at, metadata, paused_at, updated_at
FROM updated_queue
"
    );
}
