/// This file is @generated by sqlc-gen-rust.
pub async fn pg_advisory_xact_lock<'e, E>(db: E, key: i64) -> Result<(), sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    sqlx::query("
SELECT pg_advisory_xact_lock($1)
"
    ).bind(key).execute(db).await?;
    Ok(())
}
pub async fn pg_notify_many<'e, E>(
    db: E,
    topic: String,
    payload: Vec<String>,
) -> Result<(), sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    sqlx::query(
            "
WITH topic_to_notify AS (
    SELECT
        concat(current_schema(), '.', $1::text) AS topic,
        unnest($2::text[]) AS payload
)
SELECT pg_notify(
    topic_to_notify.topic,
    topic_to_notify.payload
  )
FROM topic_to_notify
",
        )
        .bind(topic)
        .bind(payload)
        .execute(db)
        .await?;
    Ok(())
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct ClientCreateOrSetUpdatedAtInfo {
    pub id: String,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub updated_at: Option<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct ClientCreateOrSetUpdatedAtRow {
    pub id: String,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}
pub async fn client_create_or_set_updated_at<'e, E>(
    db: E,
    client_create_or_set_updated_at_info: ClientCreateOrSetUpdatedAtInfo,
) -> Result<ClientCreateOrSetUpdatedAtRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: ClientCreateOrSetUpdatedAtRow = sqlx::query_as(
            "
INSERT INTO river_client (
    id,
    metadata,
    paused_at,
    updated_at
) VALUES (
    $1,
    coalesce($2::jsonb, '{}'::jsonb),
    coalesce($3::timestamptz, NULL),
    coalesce($4::timestamptz, now())
) ON CONFLICT (name) DO UPDATE
SET
    updated_at = coalesce($4::timestamptz, now())
RETURNING id, created_at, metadata, paused_at, updated_at
",
        )
        .bind(client_create_or_set_updated_at_info.id)
        .bind(client_create_or_set_updated_at_info.metadata)
        .bind(client_create_or_set_updated_at_info.paused_at)
        .bind(client_create_or_set_updated_at_info.updated_at)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct ClientQueueCreateOrSetUpdatedAtManyInfo {
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub name: Vec<String>,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub river_client_id: String,
    pub updated_at: Option<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct ClientQueueCreateOrSetUpdatedAtManyRow {
    pub river_client_id: String,
    pub name: String,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub max_workers: i64,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub num_jobs_completed: i64,
    pub num_jobs_running: i64,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}
pub async fn client_queue_create_or_set_updated_at_many<'e, E>(
    db: E,
    client_queue_create_or_set_updated_at_many_info: ClientQueueCreateOrSetUpdatedAtManyInfo,
) -> Result<ClientQueueCreateOrSetUpdatedAtManyRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: ClientQueueCreateOrSetUpdatedAtManyRow = sqlx::query_as(
            "
INSERT INTO river_client_queue (
    metadata,
    name,
    paused_at,
    river_client_id,
    updated_at
) VALUES (
    coalesce($1::jsonb, '{}'),
    unnest($2::text[]),
    coalesce($3::timestamptz, NULL),
    $4,
    coalesce($5::timestamptz, now())
) ON CONFLICT (name) DO UPDATE
SET
    updated_at = coalesce($5::timestamptz, now())
RETURNING river_client_id, name, created_at, max_workers, metadata, num_jobs_completed, num_jobs_running, updated_at
",
        )
        .bind(client_queue_create_or_set_updated_at_many_info.metadata)
        .bind(client_queue_create_or_set_updated_at_many_info.name)
        .bind(client_queue_create_or_set_updated_at_many_info.paused_at)
        .bind(client_queue_create_or_set_updated_at_many_info.river_client_id)
        .bind(client_queue_create_or_set_updated_at_many_info.updated_at)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobCancelInfo {
    pub id: i64,
    pub control_topic: String,
    pub cancel_attempted_at: sqlx::types::Json<serde_json::Value>,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobCancelRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_cancel<'e, E>(
    db: E,
    job_cancel_info: JobCancelInfo,
) -> Result<JobCancelRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: JobCancelRow = sqlx::query_as(
            "
WITH locked_job AS (
    SELECT
        id, queue, state, finalized_at
    FROM river_job
    WHERE river_job.id = $1
    FOR UPDATE
),
notification AS (
    SELECT
        id,
        pg_notify(
            concat(current_schema(), '.', $2::text),
            json_build_object('action', 'cancel', 'job_id', id, 'queue', queue)::text
        )
    FROM
        locked_job
    WHERE
        state NOT IN ('cancelled', 'completed', 'discarded')
        AND finalized_at IS NULL
),
updated_job AS (
    UPDATE river_job
    SET
        -- If the job is actively running, we want to let its current client and
        -- producer handle the cancellation. Otherwise, immediately cancel it.
        state = CASE WHEN state = 'running' THEN state ELSE 'cancelled' END,
        finalized_at = CASE WHEN state = 'running' THEN finalized_at ELSE now() END,
        -- Mark the job as cancelled by query so that the rescuer knows not to
        -- rescue it, even if it gets stuck in the running state:
        metadata = jsonb_set(metadata, '{cancel_attempted_at}'::text[], $3::jsonb, true)
    FROM notification
    WHERE river_job.id = notification.id
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $1::bigint
    AND id NOT IN (SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
",
        )
        .bind(job_cancel_info.id)
        .bind(job_cancel_info.control_topic)
        .bind(job_cancel_info.cancel_attempted_at)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
pub async fn job_count_by_state<'e, E>(
    db: E,
    state: sqlx::types::Json<serde_json::Value>,
) -> Result<i64, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: i64 = sqlx::query_scalar(
            "
SELECT count(*)
FROM river_job
WHERE state = $1
",
        )
        .bind(state)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobDeleteRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_delete<'e, E>(db: E, id: i64) -> Result<JobDeleteRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: JobDeleteRow = sqlx::query_as(
            "
WITH job_to_delete AS (
    SELECT id
    FROM river_job
    WHERE river_job.id = $1
    FOR UPDATE
),
deleted_job AS (
    DELETE
    FROM river_job
    USING job_to_delete
    WHERE river_job.id = job_to_delete.id
        -- Do not touch running jobs:
        AND river_job.state != 'running'
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $1::bigint
    AND id NOT IN (SELECT id FROM deleted_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM deleted_job
",
        )
        .bind(id)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobDeleteBeforeInfo {
    pub cancelled_finalized_at_horizon: chrono::DateTime<chrono::Utc>,
    pub completed_finalized_at_horizon: chrono::DateTime<chrono::Utc>,
    pub discarded_finalized_at_horizon: chrono::DateTime<chrono::Utc>,
    pub max: i64,
}
pub async fn job_delete_before<'e, E>(
    db: E,
    job_delete_before_info: JobDeleteBeforeInfo,
) -> Result<i64, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: i64 = sqlx::query_scalar(
            "
WITH deleted_jobs AS (
    DELETE FROM river_job
    WHERE id IN (
        SELECT id
        FROM river_job
        WHERE
            (state = 'cancelled' AND finalized_at < $1::timestamptz) OR
            (state = 'completed' AND finalized_at < $2::timestamptz) OR
            (state = 'discarded' AND finalized_at < $3::timestamptz)
        ORDER BY id
        LIMIT $4::bigint
    )
    RETURNING id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
)
SELECT count(*)
FROM deleted_jobs
",
        )
        .bind(job_delete_before_info.cancelled_finalized_at_horizon)
        .bind(job_delete_before_info.completed_finalized_at_horizon)
        .bind(job_delete_before_info.discarded_finalized_at_horizon)
        .bind(job_delete_before_info.max)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobGetAvailableInfo {
    pub attempted_by: String,
    pub queue: String,
    pub now: Option<chrono::DateTime<chrono::Utc>>,
    pub max: i32,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobGetAvailableRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_get_available<'e, E>(
    db: E,
    job_get_available_info: JobGetAvailableInfo,
) -> Result<Vec<JobGetAvailableRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<JobGetAvailableRow> = sqlx::query_as(
            "
WITH locked_jobs AS (
    SELECT
        id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
    FROM
        river_job
    WHERE
        state = 'available'
        AND queue = $2::text
        AND scheduled_at <= coalesce($3::timestamptz, now())
    ORDER BY
        priority ASC,
        scheduled_at ASC,
        id ASC
    LIMIT $4::integer
    FOR UPDATE
    SKIP LOCKED
)
UPDATE
    river_job
SET
    state = 'running',
    attempt = river_job.attempt + 1,
    attempted_at = now(),
    attempted_by = array_append(river_job.attempted_by, $1::text)
FROM
    locked_jobs
WHERE
    river_job.id = locked_jobs.id
RETURNING
    river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
",
        )
        .bind(job_get_available_info.attempted_by)
        .bind(job_get_available_info.queue)
        .bind(job_get_available_info.now)
        .bind(job_get_available_info.max)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobGetByKindAndUniquePropertiesInfo {
    pub kind: String,
    pub by_args: bool,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub by_created_at: bool,
    pub created_at_begin: chrono::DateTime<chrono::Utc>,
    pub created_at_end: chrono::DateTime<chrono::Utc>,
    pub by_queue: bool,
    pub queue: String,
    pub by_state: bool,
    pub state: Vec<String>,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobGetByKindAndUniquePropertiesRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_get_by_kind_and_unique_properties<'e, E>(
    db: E,
    job_get_by_kind_and_unique_properties_info: JobGetByKindAndUniquePropertiesInfo,
) -> Result<JobGetByKindAndUniquePropertiesRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: JobGetByKindAndUniquePropertiesRow = sqlx::query_as(
            "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE kind = $1
    AND CASE WHEN $2::boolean THEN args = $3 ELSE true END
    AND CASE WHEN $4::boolean THEN tstzrange($5::timestamptz, $6::timestamptz, '[)') @> created_at ELSE true END
    AND CASE WHEN $7::boolean THEN queue = $8 ELSE true END
    AND CASE WHEN $9::boolean THEN state::text = any($10::text[]) ELSE true END
",
        )
        .bind(job_get_by_kind_and_unique_properties_info.kind)
        .bind(job_get_by_kind_and_unique_properties_info.by_args)
        .bind(job_get_by_kind_and_unique_properties_info.args)
        .bind(job_get_by_kind_and_unique_properties_info.by_created_at)
        .bind(job_get_by_kind_and_unique_properties_info.created_at_begin)
        .bind(job_get_by_kind_and_unique_properties_info.created_at_end)
        .bind(job_get_by_kind_and_unique_properties_info.by_queue)
        .bind(job_get_by_kind_and_unique_properties_info.queue)
        .bind(job_get_by_kind_and_unique_properties_info.by_state)
        .bind(job_get_by_kind_and_unique_properties_info.state)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobGetByKindManyRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_get_by_kind_many<'e, E>(
    db: E,
    kind: Vec<String>,
) -> Result<Vec<JobGetByKindManyRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<JobGetByKindManyRow> = sqlx::query_as(
            "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE kind = any($1::text[])
ORDER BY id
",
        )
        .bind(kind)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobGetByIdRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_get_by_id<'e, E>(db: E, id: i64) -> Result<JobGetByIdRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: JobGetByIdRow = sqlx::query_as(
            "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $1
LIMIT 1
",
        )
        .bind(id)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobGetByIdManyRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_get_by_id_many<'e, E>(
    db: E,
    id: Vec<i64>,
) -> Result<Vec<JobGetByIdManyRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<JobGetByIdManyRow> = sqlx::query_as(
            "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = any($1::bigint[])
ORDER BY id
",
        )
        .bind(id)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobGetStuckRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_get_stuck<'e, E>(
    db: E,
    stuck_horizon: chrono::DateTime<chrono::Utc>,
    max: i32,
) -> Result<Vec<JobGetStuckRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<JobGetStuckRow> = sqlx::query_as(
            "
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE state = 'running'
    AND attempted_at < $1::timestamptz
ORDER BY id
LIMIT $2
",
        )
        .bind(stuck_horizon)
        .bind(max)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobInsertFastManyInfo {
    pub args: Vec<sqlx::types::Json<serde_json::Value>>,
    pub kind: Vec<String>,
    pub max_attempts: Vec<i16>,
    pub metadata: Vec<sqlx::types::Json<serde_json::Value>>,
    pub priority: Vec<i16>,
    pub queue: Vec<String>,
    pub scheduled_at: Vec<chrono::DateTime<chrono::Utc>>,
    pub state: Vec<String>,
    pub tags: Vec<String>,
    pub unique_key: Vec<Vec<u8>>,
    pub unique_states: Vec<sqlx::types::Json<serde_json::Value>>,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobInsertFastManyRow {
    pub river_job: Option<sqlx::types::Json<serde_json::Value>>,
    pub unique_skipped_as_duplicate: bool,
}
pub async fn job_insert_fast_many<'e, E>(
    db: E,
    job_insert_fast_many_info: JobInsertFastManyInfo,
) -> Result<Vec<JobInsertFastManyRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<JobInsertFastManyRow> = sqlx::query_as(
            "
INSERT INTO river_job(
    args,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key,
    unique_states
) SELECT
    unnest($1::jsonb[]),
    unnest($2::text[]),
    unnest($3::smallint[]),
    unnest($4::jsonb[]),
    unnest($5::smallint[]),
    unnest($6::text[]),
    unnest($7::timestamptz[]),
    -- To avoid requiring pgx users to register the OID of the river_job_state[]
    -- type, we cast the array to text[] and then to river_job_state.
    unnest($8::text[])::river_job_state,
    -- Unnest on a multi-dimensional array will fully flatten the array, so we
    -- encode the tag list as a comma-separated string and split it in the
    -- query.
    string_to_array(unnest($9::text[]), ','),

    unnest($10::bytea[]),
    unnest($11::bit(8)[])

ON CONFLICT (unique_key)
    WHERE unique_key IS NOT NULL
      AND unique_states IS NOT NULL
      AND river_job_state_in_bitmask(unique_states, state)
    -- Something needs to be updated for a row to be returned on a conflict.
    DO UPDATE SET kind = EXCLUDED.kind
RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states, (xmax != 0) AS unique_skipped_as_duplicate
",
        )
        .bind(job_insert_fast_many_info.args)
        .bind(job_insert_fast_many_info.kind)
        .bind(job_insert_fast_many_info.max_attempts)
        .bind(job_insert_fast_many_info.metadata)
        .bind(job_insert_fast_many_info.priority)
        .bind(job_insert_fast_many_info.queue)
        .bind(job_insert_fast_many_info.scheduled_at)
        .bind(job_insert_fast_many_info.state)
        .bind(job_insert_fast_many_info.tags)
        .bind(job_insert_fast_many_info.unique_key)
        .bind(job_insert_fast_many_info.unique_states)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobInsertFastManyNoReturningInfo {
    pub args: Vec<sqlx::types::Json<serde_json::Value>>,
    pub kind: Vec<String>,
    pub max_attempts: Vec<i16>,
    pub metadata: Vec<sqlx::types::Json<serde_json::Value>>,
    pub priority: Vec<i16>,
    pub queue: Vec<String>,
    pub scheduled_at: Vec<chrono::DateTime<chrono::Utc>>,
    pub state: Vec<sqlx::types::Json<serde_json::Value>>,
    pub tags: Vec<String>,
    pub unique_key: Vec<Vec<u8>>,
    pub unique_states: Vec<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_insert_fast_many_no_returning<'e, E>(
    db: E,
    job_insert_fast_many_no_returning_info: JobInsertFastManyNoReturningInfo,
) -> Result<u64, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec = sqlx::query(
            "
INSERT INTO river_job(
    args,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key,
    unique_states
) SELECT
    unnest($1::jsonb[]),
    unnest($2::text[]),
    unnest($3::smallint[]),
    unnest($4::jsonb[]),
    unnest($5::smallint[]),
    unnest($6::text[]),
    unnest($7::timestamptz[]),
    unnest($8::river_job_state[]),

    -- lib/pq really, REALLY does not play nicely with multi-dimensional arrays,
    -- so instead we pack each set of tags into a string, send them through,
    -- then unpack them here into an array to put in each row. This isn't
    -- necessary in the Pgx driver where copyfrom is used instead.
    string_to_array(unnest($9::text[]), ','),

    unnest($10::bytea[]),
    unnest($11::bit(8)[])

ON CONFLICT (unique_key)
    WHERE unique_key IS NOT NULL
      AND unique_states IS NOT NULL
      AND river_job_state_in_bitmask(unique_states, state)
DO NOTHING
",
        )
        .bind(job_insert_fast_many_no_returning_info.args)
        .bind(job_insert_fast_many_no_returning_info.kind)
        .bind(job_insert_fast_many_no_returning_info.max_attempts)
        .bind(job_insert_fast_many_no_returning_info.metadata)
        .bind(job_insert_fast_many_no_returning_info.priority)
        .bind(job_insert_fast_many_no_returning_info.queue)
        .bind(job_insert_fast_many_no_returning_info.scheduled_at)
        .bind(job_insert_fast_many_no_returning_info.state)
        .bind(job_insert_fast_many_no_returning_info.tags)
        .bind(job_insert_fast_many_no_returning_info.unique_key)
        .bind(job_insert_fast_many_no_returning_info.unique_states)
        .execute(db)
        .await?;
    Ok(rec.rows_affected())
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobInsertFullInfo {
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub created_at: Option<chrono::DateTime<chrono::Utc>>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub scheduled_at: Option<chrono::DateTime<chrono::Utc>>,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobInsertFullRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_insert_full<'e, E>(
    db: E,
    job_insert_full_info: JobInsertFullInfo,
) -> Result<JobInsertFullRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: JobInsertFullRow = sqlx::query_as(
            "
INSERT INTO river_job(
    args,
    attempt,
    attempted_at,
    created_at,
    errors,
    finalized_at,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key,
    unique_states
) VALUES (
    $1::jsonb,
    coalesce($2::smallint, 0),
    $3,
    coalesce($4::timestamptz, now()),
    $5,
    $6,
    $7,
    $8::smallint,
    coalesce($9::jsonb, '{}'),
    $10,
    $11,
    coalesce($12::timestamptz, now()),
    $13,
    coalesce($14::varchar(255)[], '{}'),
    $15,
    $16
) RETURNING id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
",
        )
        .bind(job_insert_full_info.args)
        .bind(job_insert_full_info.attempt)
        .bind(job_insert_full_info.attempted_at)
        .bind(job_insert_full_info.created_at)
        .bind(job_insert_full_info.errors)
        .bind(job_insert_full_info.finalized_at)
        .bind(job_insert_full_info.kind)
        .bind(job_insert_full_info.max_attempts)
        .bind(job_insert_full_info.metadata)
        .bind(job_insert_full_info.priority)
        .bind(job_insert_full_info.queue)
        .bind(job_insert_full_info.scheduled_at)
        .bind(job_insert_full_info.state)
        .bind(job_insert_full_info.tags)
        .bind(job_insert_full_info.unique_key)
        .bind(job_insert_full_info.unique_states)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobRescueManyInfo {
    pub id: Vec<i64>,
    pub error: Vec<sqlx::types::Json<serde_json::Value>>,
    pub finalized_at: Vec<chrono::DateTime<chrono::Utc>>,
    pub scheduled_at: Vec<chrono::DateTime<chrono::Utc>>,
    pub state: Vec<String>,
}
pub async fn job_rescue_many<'e, E>(
    db: E,
    job_rescue_many_info: JobRescueManyInfo,
) -> Result<(), sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    sqlx::query(
            "
UPDATE river_job
SET
    errors = array_append(errors, updated_job.error),
    finalized_at = updated_job.finalized_at,
    scheduled_at = updated_job.scheduled_at,
    state = updated_job.state
FROM (
    SELECT
        unnest($1::bigint[]) AS id,
        unnest($2::jsonb[]) AS error,
        nullif(unnest($3::timestamptz[]), '0001-01-01 00:00:00 +0000') AS finalized_at,
        unnest($4::timestamptz[]) AS scheduled_at,
        unnest($5::text[])::river_job_state AS state
) AS updated_job
WHERE river_job.id = updated_job.id
",
        )
        .bind(job_rescue_many_info.id)
        .bind(job_rescue_many_info.error)
        .bind(job_rescue_many_info.finalized_at)
        .bind(job_rescue_many_info.scheduled_at)
        .bind(job_rescue_many_info.state)
        .execute(db)
        .await?;
    Ok(())
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobRetryRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_retry<'e, E>(db: E, id: i64) -> Result<JobRetryRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: JobRetryRow = sqlx::query_as(
            "
WITH job_to_update AS (
    SELECT id
    FROM river_job
    WHERE river_job.id = $1
    FOR UPDATE
),
updated_job AS (
    UPDATE river_job
    SET
        state = 'available',
        scheduled_at = now(),
        max_attempts = CASE WHEN attempt = max_attempts THEN max_attempts + 1 ELSE max_attempts END,
        finalized_at = NULL
    FROM job_to_update
    WHERE river_job.id = job_to_update.id
        -- Do not touch running jobs:
        AND river_job.state != 'running'
        -- If the job is already available with a prior scheduled_at, leave it alone.
        AND NOT (river_job.state = 'available' AND river_job.scheduled_at < now())
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $1::bigint
    AND id NOT IN (SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
",
        )
        .bind(id)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobScheduleRow {
    pub river_job: Option<sqlx::types::Json<serde_json::Value>>,
    pub conflict_discarded: bool,
}
pub async fn job_schedule<'e, E>(
    db: E,
    now: chrono::DateTime<chrono::Utc>,
    max: i64,
) -> Result<Vec<JobScheduleRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<JobScheduleRow> = sqlx::query_as(
            "
WITH jobs_to_schedule AS (
    SELECT
        id,
        unique_key,
        unique_states,
        priority,
        scheduled_at
    FROM river_job
    WHERE
        state IN ('retryable', 'scheduled')
        AND queue IS NOT NULL
        AND priority >= 0
        AND scheduled_at <= $1::timestamptz
    ORDER BY
        priority,
        scheduled_at,
        id
    LIMIT $2::bigint
    FOR UPDATE
),
jobs_with_rownum AS (
    SELECT
        id, unique_key, unique_states, priority, scheduled_at,
        CASE
            WHEN unique_key IS NOT NULL AND unique_states IS NOT NULL THEN
                ROW_NUMBER() OVER (
                    PARTITION BY unique_key
                    ORDER BY priority, scheduled_at, id
                )
            ELSE NULL
        END AS row_num
    FROM jobs_to_schedule
),
unique_conflicts AS (
    SELECT river_job.unique_key
    FROM river_job
    JOIN jobs_with_rownum
        ON river_job.unique_key = jobs_with_rownum.unique_key
        AND river_job.id != jobs_with_rownum.id
    WHERE
        river_job.unique_key IS NOT NULL
        AND river_job.unique_states IS NOT NULL
        AND river_job_state_in_bitmask(river_job.unique_states, river_job.state)
),
job_updates AS (
    SELECT
        job.id,
        job.unique_key,
        job.unique_states,
        CASE
            WHEN job.row_num IS NULL THEN 'available'::river_job_state
            WHEN uc.unique_key IS NOT NULL THEN 'discarded'::river_job_state
            WHEN job.row_num = 1 THEN 'available'::river_job_state
            ELSE 'discarded'::river_job_state
        END AS new_state,
        (job.row_num IS NOT NULL AND (uc.unique_key IS NOT NULL OR job.row_num > 1)) AS finalized_at_do_update,
        (job.row_num IS NOT NULL AND (uc.unique_key IS NOT NULL OR job.row_num > 1)) AS metadata_do_update
    FROM jobs_with_rownum job
    LEFT JOIN unique_conflicts uc ON job.unique_key = uc.unique_key
),
updated_jobs AS (
    UPDATE river_job
    SET
        state        = job_updates.new_state,
        finalized_at = CASE WHEN job_updates.finalized_at_do_update THEN $1::timestamptz
                            ELSE river_job.finalized_at END,
        metadata     = CASE WHEN job_updates.metadata_do_update THEN river_job.metadata || '{\"unique_key_conflict\": \"scheduler_discarded\"}'::jsonb
                            ELSE river_job.metadata END
    FROM job_updates
    WHERE river_job.id = job_updates.id
    RETURNING
        river_job.id,
        job_updates.new_state = 'discarded'::river_job_state AS conflict_discarded
)
SELECT
    river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states,
    updated_jobs.conflict_discarded
FROM river_job
JOIN updated_jobs ON river_job.id = updated_jobs.id
",
        )
        .bind(now)
        .bind(max)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobSetCompleteIfRunningManyRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_set_complete_if_running_many<'e, E>(
    db: E,
    id: Vec<i64>,
    finalized_at: Vec<chrono::DateTime<chrono::Utc>>,
) -> Result<Vec<JobSetCompleteIfRunningManyRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<JobSetCompleteIfRunningManyRow> = sqlx::query_as(
            "
WITH job_to_finalized_at AS (
    SELECT
        unnest($1::bigint[]) AS id,
        unnest($2::timestamptz[]) AS finalized_at
),
job_to_update AS (
    SELECT river_job.id, job_to_finalized_at.finalized_at
    FROM river_job, job_to_finalized_at
    WHERE river_job.id = job_to_finalized_at.id
        AND river_job.state = 'running'
    FOR UPDATE
),
updated_job AS (
    UPDATE river_job
    SET
        finalized_at = job_to_update.finalized_at,
        state = 'completed'
    FROM job_to_update
    WHERE river_job.id = job_to_update.id
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id IN (SELECT id FROM job_to_finalized_at EXCEPT SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
",
        )
        .bind(id)
        .bind(finalized_at)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobSetStateIfRunningInfo {
    pub state: sqlx::types::Json<serde_json::Value>,
    pub id: i64,
    pub finalized_at_do_update: bool,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub error_do_update: bool,
    pub error: sqlx::types::Json<serde_json::Value>,
    pub max_attempts_update: bool,
    pub max_attempts: i16,
    pub scheduled_at_do_update: bool,
    pub scheduled_at: Option<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobSetStateIfRunningRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_set_state_if_running<'e, E>(
    db: E,
    job_set_state_if_running_info: JobSetStateIfRunningInfo,
) -> Result<JobSetStateIfRunningRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: JobSetStateIfRunningRow = sqlx::query_as(
            "
WITH job_to_update AS (
    SELECT
        id,
        $1::river_job_state IN ('retryable', 'scheduled') AND metadata ? 'cancel_attempted_at' AS should_cancel
    FROM river_job
    WHERE id = $2::bigint
    FOR UPDATE
),
updated_job AS (
    UPDATE river_job
    SET
        state        = CASE WHEN should_cancel                                           THEN 'cancelled'::river_job_state
                            ELSE $1::river_job_state END,
        finalized_at = CASE WHEN should_cancel                                           THEN now()
                            WHEN $3::boolean                        THEN $4
                            ELSE finalized_at END,
        errors       = CASE WHEN $5::boolean                               THEN array_append(errors, $6::jsonb)
                            ELSE errors       END,
        max_attempts = CASE WHEN NOT should_cancel AND $7::boolean     THEN $8
                            ELSE max_attempts END,
        scheduled_at = CASE WHEN NOT should_cancel AND $9::boolean  THEN $10::timestamptz
                            ELSE scheduled_at END
    FROM job_to_update
    WHERE river_job.id = job_to_update.id
        AND river_job.state = 'running'
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = $2::bigint
    AND id NOT IN (SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
",
        )
        .bind(job_set_state_if_running_info.state)
        .bind(job_set_state_if_running_info.id)
        .bind(job_set_state_if_running_info.finalized_at_do_update)
        .bind(job_set_state_if_running_info.finalized_at)
        .bind(job_set_state_if_running_info.error_do_update)
        .bind(job_set_state_if_running_info.error)
        .bind(job_set_state_if_running_info.max_attempts_update)
        .bind(job_set_state_if_running_info.max_attempts)
        .bind(job_set_state_if_running_info.scheduled_at_do_update)
        .bind(job_set_state_if_running_info.scheduled_at)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobSetStateIfRunningManyInfo {
    pub ids: Vec<i64>,
    pub state: Vec<String>,
    pub finalized_at_do_update: Vec<bool>,
    pub finalized_at: Vec<chrono::DateTime<chrono::Utc>>,
    pub errors_do_update: Vec<bool>,
    pub errors: Vec<sqlx::types::Json<serde_json::Value>>,
    pub max_attempts_do_update: Vec<bool>,
    pub max_attempts: Vec<i32>,
    pub scheduled_at_do_update: Vec<bool>,
    pub scheduled_at: Vec<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobSetStateIfRunningManyRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_set_state_if_running_many<'e, E>(
    db: E,
    job_set_state_if_running_many_info: JobSetStateIfRunningManyInfo,
) -> Result<Vec<JobSetStateIfRunningManyRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<JobSetStateIfRunningManyRow> = sqlx::query_as(
            "
WITH job_input AS (
    SELECT
        unnest($1::bigint[]) AS id,
        -- To avoid requiring pgx users to register the OID of the river_job_state[]
        -- type, we cast the array to text[] and then to river_job_state.
        unnest($2::text[])::river_job_state AS state,
        unnest($3::boolean[]) AS finalized_at_do_update,
        unnest($4::timestamptz[]) AS finalized_at,
        unnest($5::boolean[]) AS errors_do_update,
        unnest($6::jsonb[]) AS errors,
        unnest($7::boolean[]) AS max_attempts_do_update,
        unnest($8::int[]) AS max_attempts,
        unnest($9::boolean[]) AS scheduled_at_do_update,
        unnest($10::timestamptz[]) AS scheduled_at
),
job_to_update AS (
    SELECT
        river_job.id,
        job_input.state,
        job_input.finalized_at,
        job_input.errors,
        job_input.max_attempts,
        job_input.scheduled_at,
        (job_input.state IN ('retryable', 'scheduled') AND river_job.metadata ? 'cancel_attempted_at') AS should_cancel,
        job_input.finalized_at_do_update,
        job_input.errors_do_update,
        job_input.max_attempts_do_update,
        job_input.scheduled_at_do_update
    FROM river_job
    JOIN job_input ON river_job.id = job_input.id
    WHERE river_job.state = 'running'
    FOR UPDATE
),
updated_job AS (
    UPDATE river_job
    SET
        state        = CASE WHEN job_to_update.should_cancel THEN 'cancelled'::river_job_state
                            ELSE job_to_update.state END,
        finalized_at = CASE WHEN job_to_update.should_cancel THEN now()
                            WHEN job_to_update.finalized_at_do_update THEN job_to_update.finalized_at
                            ELSE river_job.finalized_at END,
        errors       = CASE WHEN job_to_update.errors_do_update THEN array_append(river_job.errors, job_to_update.errors)
                            ELSE river_job.errors END,
        max_attempts = CASE WHEN NOT job_to_update.should_cancel AND job_to_update.max_attempts_do_update THEN job_to_update.max_attempts
                            ELSE river_job.max_attempts END,
        scheduled_at = CASE WHEN NOT job_to_update.should_cancel AND job_to_update.scheduled_at_do_update THEN job_to_update.scheduled_at
                            ELSE river_job.scheduled_at END
    FROM job_to_update
    WHERE river_job.id = job_to_update.id
    RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states
)
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id IN (SELECT id FROM job_input)
  AND id NOT IN (SELECT id FROM updated_job)
UNION
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM updated_job
",
        )
        .bind(job_set_state_if_running_many_info.ids)
        .bind(job_set_state_if_running_many_info.state)
        .bind(job_set_state_if_running_many_info.finalized_at_do_update)
        .bind(job_set_state_if_running_many_info.finalized_at)
        .bind(job_set_state_if_running_many_info.errors_do_update)
        .bind(job_set_state_if_running_many_info.errors)
        .bind(job_set_state_if_running_many_info.max_attempts_do_update)
        .bind(job_set_state_if_running_many_info.max_attempts)
        .bind(job_set_state_if_running_many_info.scheduled_at_do_update)
        .bind(job_set_state_if_running_many_info.scheduled_at)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobUpdateInfo {
    pub attempt_do_update: bool,
    pub attempt: i16,
    pub attempted_at_do_update: bool,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub errors_do_update: bool,
    pub errors: Vec<sqlx::types::Json<serde_json::Value>>,
    pub finalized_at_do_update: bool,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub state_do_update: bool,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub id: i64,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobUpdateRow {
    pub id: i64,
    pub args: sqlx::types::Json<serde_json::Value>,
    pub attempt: i16,
    pub attempted_at: Option<chrono::DateTime<chrono::Utc>>,
    pub attempted_by: Option<Vec<String>>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub errors: Option<Vec<sqlx::types::Json<serde_json::Value>>>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub tags: Vec<sqlx::types::Json<serde_json::Value>>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_update<'e, E>(
    db: E,
    job_update_info: JobUpdateInfo,
) -> Result<JobUpdateRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: JobUpdateRow = sqlx::query_as(
            "
UPDATE river_job
SET
    attempt = CASE WHEN $1::boolean THEN $2 ELSE attempt END,
    attempted_at = CASE WHEN $3::boolean THEN $4 ELSE attempted_at END,
    errors = CASE WHEN $5::boolean THEN $6::jsonb[] ELSE errors END,
    finalized_at = CASE WHEN $7::boolean THEN $8 ELSE finalized_at END,
    state = CASE WHEN $9::boolean THEN $10 ELSE state END
WHERE id = $11
RETURNING id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
",
        )
        .bind(job_update_info.attempt_do_update)
        .bind(job_update_info.attempt)
        .bind(job_update_info.attempted_at_do_update)
        .bind(job_update_info.attempted_at)
        .bind(job_update_info.errors_do_update)
        .bind(job_update_info.errors)
        .bind(job_update_info.finalized_at_do_update)
        .bind(job_update_info.finalized_at)
        .bind(job_update_info.state_do_update)
        .bind(job_update_info.state)
        .bind(job_update_info.id)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct JobInsertFastManyCopyFromInfo {
    pub args: sqlx::types::Json<serde_json::Value>,
    pub finalized_at: Option<chrono::DateTime<chrono::Utc>>,
    pub kind: String,
    pub max_attempts: i16,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub priority: i16,
    pub queue: String,
    pub scheduled_at: chrono::DateTime<chrono::Utc>,
    pub state: sqlx::types::Json<serde_json::Value>,
    pub tags: Vec<String>,
    pub unique_key: Option<Vec<u8>>,
    pub unique_states: Option<sqlx::types::Json<serde_json::Value>>,
}
pub async fn job_insert_fast_many_copy_from<'e, E>(
    db: E,
    job_insert_fast_many_copy_from_info: JobInsertFastManyCopyFromInfo,
) -> Result<(), sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    sqlx::query(
            "
INSERT INTO river_job(
    args,
    finalized_at,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key,
    unique_states
) VALUES (
    $1,
    $2,
    $3,
    $4,
    $5,
    $6,
    $7,
    $8,
    $9,
    $10,
    $11,
    $12
)
",
        )
        .bind(job_insert_fast_many_copy_from_info.args)
        .bind(job_insert_fast_many_copy_from_info.finalized_at)
        .bind(job_insert_fast_many_copy_from_info.kind)
        .bind(job_insert_fast_many_copy_from_info.max_attempts)
        .bind(job_insert_fast_many_copy_from_info.metadata)
        .bind(job_insert_fast_many_copy_from_info.priority)
        .bind(job_insert_fast_many_copy_from_info.queue)
        .bind(job_insert_fast_many_copy_from_info.scheduled_at)
        .bind(job_insert_fast_many_copy_from_info.state)
        .bind(job_insert_fast_many_copy_from_info.tags)
        .bind(job_insert_fast_many_copy_from_info.unique_key)
        .bind(job_insert_fast_many_copy_from_info.unique_states)
        .execute(db)
        .await?;
    Err(sqlx::Error::TypeNotFound {
        type_name: String::from(":copyfrom"),
    })
}
pub async fn leader_attempt_elect<'e, E>(
    db: E,
    leader_id: String,
    ttl: chrono::Duration,
) -> Result<u64, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec = sqlx::query(
            "
INSERT INTO river_leader(leader_id, elected_at, expires_at)
    VALUES ($1, now(), now() + $2::interval)
ON CONFLICT (name)
    DO NOTHING
",
        )
        .bind(leader_id)
        .bind(ttl)
        .execute(db)
        .await?;
    Ok(rec.rows_affected())
}
pub async fn leader_attempt_reelect<'e, E>(
    db: E,
    leader_id: String,
    ttl: chrono::Duration,
) -> Result<u64, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec = sqlx::query(
            "
INSERT INTO river_leader(leader_id, elected_at, expires_at)
    VALUES ($1, now(), now() + $2::interval)
ON CONFLICT (name)
    DO UPDATE SET
        expires_at = now() + $2
    WHERE
        river_leader.leader_id = $1
",
        )
        .bind(leader_id)
        .bind(ttl)
        .execute(db)
        .await?;
    Ok(rec.rows_affected())
}
pub async fn leader_delete_expired<'e, E>(db: E) -> Result<u64, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec = sqlx::query("
DELETE FROM river_leader
WHERE expires_at < now()
"
    )
        .execute(db)
        .await?;
    Ok(rec.rows_affected())
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct LeaderGetElectedLeaderRow {
    pub elected_at: chrono::DateTime<chrono::Utc>,
    pub expires_at: chrono::DateTime<chrono::Utc>,
    pub leader_id: String,
    pub name: String,
}
pub async fn leader_get_elected_leader<'e, E>(
    db: E,
) -> Result<LeaderGetElectedLeaderRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: LeaderGetElectedLeaderRow = sqlx::query_as(
            "
SELECT elected_at, expires_at, leader_id, name
FROM river_leader
",
        )
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct LeaderInsertInfo {
    pub elected_at: Option<chrono::DateTime<chrono::Utc>>,
    pub expires_at: Option<chrono::DateTime<chrono::Utc>>,
    pub ttl: chrono::Duration,
    pub leader_id: String,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct LeaderInsertRow {
    pub elected_at: chrono::DateTime<chrono::Utc>,
    pub expires_at: chrono::DateTime<chrono::Utc>,
    pub leader_id: String,
    pub name: String,
}
pub async fn leader_insert<'e, E>(
    db: E,
    leader_insert_info: LeaderInsertInfo,
) -> Result<LeaderInsertRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: LeaderInsertRow = sqlx::query_as(
            "
INSERT INTO river_leader(
    elected_at,
    expires_at,
    leader_id
) VALUES (
    coalesce($1::timestamptz, now()),
    coalesce($2::timestamptz, now() + $3::interval),
    $4
) RETURNING elected_at, expires_at, leader_id, name
",
        )
        .bind(leader_insert_info.elected_at)
        .bind(leader_insert_info.expires_at)
        .bind(leader_insert_info.ttl)
        .bind(leader_insert_info.leader_id)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
pub async fn leader_resign<'e, E>(
    db: E,
    leader_id: String,
    leadership_topic: String,
) -> Result<u64, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec = sqlx::query(
            "
WITH currently_held_leaders AS (
  SELECT elected_at, expires_at, leader_id, name
  FROM river_leader
  WHERE leader_id = $1::text
  FOR UPDATE
),
notified_resignations AS (
    SELECT pg_notify(
        concat(current_schema(), '.', $2::text),
        json_build_object('leader_id', leader_id, 'action', 'resigned')::text
    )
    FROM currently_held_leaders
)
DELETE FROM river_leader USING notified_resignations
",
        )
        .bind(leader_id)
        .bind(leadership_topic)
        .execute(db)
        .await?;
    Ok(rec.rows_affected())
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct RiverMigrationDeleteAssumingMainManyRow {
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub version: i64,
}
pub async fn river_migration_delete_assuming_main_many<'e, E>(
    db: E,
    version: Vec<i64>,
) -> Result<Vec<RiverMigrationDeleteAssumingMainManyRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<RiverMigrationDeleteAssumingMainManyRow> = sqlx::query_as(
            "
DELETE FROM river_migration
WHERE version = any($1::bigint[])
RETURNING
    created_at,
    version
",
        )
        .bind(version)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct RiverMigrationDeleteByLineAndVersionManyRow {
    pub line: String,
    pub version: i64,
    pub created_at: chrono::DateTime<chrono::Utc>,
}
pub async fn river_migration_delete_by_line_and_version_many<'e, E>(
    db: E,
    line: String,
    version: Vec<i64>,
) -> Result<Vec<RiverMigrationDeleteByLineAndVersionManyRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<RiverMigrationDeleteByLineAndVersionManyRow> = sqlx::query_as(
            "
DELETE FROM river_migration
WHERE line = $1
    AND version = any($2::bigint[])
RETURNING line, version, created_at
",
        )
        .bind(line)
        .bind(version)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct RiverMigrationGetAllAssumingMainRow {
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub version: i64,
}
pub async fn river_migration_get_all_assuming_main<'e, E>(
    db: E,
) -> Result<Vec<RiverMigrationGetAllAssumingMainRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<RiverMigrationGetAllAssumingMainRow> = sqlx::query_as(
            "
SELECT
    created_at,
    version
FROM river_migration
ORDER BY version
",
        )
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct RiverMigrationGetByLineRow {
    pub line: String,
    pub version: i64,
    pub created_at: chrono::DateTime<chrono::Utc>,
}
pub async fn river_migration_get_by_line<'e, E>(
    db: E,
    line: String,
) -> Result<Vec<RiverMigrationGetByLineRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<RiverMigrationGetByLineRow> = sqlx::query_as(
            "
SELECT line, version, created_at
FROM river_migration
WHERE line = $1
ORDER BY version
",
        )
        .bind(line)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct RiverMigrationInsertRow {
    pub line: String,
    pub version: i64,
    pub created_at: chrono::DateTime<chrono::Utc>,
}
pub async fn river_migration_insert<'e, E>(
    db: E,
    line: String,
    version: i64,
) -> Result<RiverMigrationInsertRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: RiverMigrationInsertRow = sqlx::query_as(
            "
INSERT INTO river_migration (
    line,
    version
) VALUES (
    $1,
    $2
) RETURNING line, version, created_at
",
        )
        .bind(line)
        .bind(version)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct RiverMigrationInsertManyRow {
    pub line: String,
    pub version: i64,
    pub created_at: chrono::DateTime<chrono::Utc>,
}
pub async fn river_migration_insert_many<'e, E>(
    db: E,
    line: String,
    version: Vec<i64>,
) -> Result<Vec<RiverMigrationInsertManyRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<RiverMigrationInsertManyRow> = sqlx::query_as(
            "
INSERT INTO river_migration (
    line,
    version
)
SELECT
    $1,
    unnest($2::bigint[])
RETURNING line, version, created_at
",
        )
        .bind(line)
        .bind(version)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct RiverMigrationInsertManyAssumingMainRow {
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub version: i64,
}
pub async fn river_migration_insert_many_assuming_main<'e, E>(
    db: E,
    version: Vec<i64>,
) -> Result<Vec<RiverMigrationInsertManyAssumingMainRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<RiverMigrationInsertManyAssumingMainRow> = sqlx::query_as(
            "
INSERT INTO river_migration (
    version
)
SELECT
    unnest($1::bigint[])
RETURNING
    created_at,
    version
",
        )
        .bind(version)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
pub async fn column_exists<'e, E>(
    db: E,
    table_name: String,
    column_name: String,
) -> Result<bool, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: bool = sqlx::query_scalar(
            "
SELECT EXISTS (
    SELECT column_name
    FROM information_schema.columns 
    WHERE table_name = $1::text
        AND table_schema = CURRENT_SCHEMA
        AND column_name = $2::text
)
",
        )
        .bind(table_name)
        .bind(column_name)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
pub async fn table_exists<'e, E>(db: E, table_name: String) -> Result<bool, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: bool = sqlx::query_scalar(
            "
SELECT CASE WHEN to_regclass($1) IS NULL THEN false
            ELSE true END
",
        )
        .bind(table_name)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct QueueCreateOrSetUpdatedAtInfo {
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub name: String,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub updated_at: Option<chrono::DateTime<chrono::Utc>>,
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct QueueCreateOrSetUpdatedAtRow {
    pub name: String,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}
pub async fn queue_create_or_set_updated_at<'e, E>(
    db: E,
    queue_create_or_set_updated_at_info: QueueCreateOrSetUpdatedAtInfo,
) -> Result<QueueCreateOrSetUpdatedAtRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: QueueCreateOrSetUpdatedAtRow = sqlx::query_as(
            "
INSERT INTO river_queue(
    created_at,
    metadata,
    name,
    paused_at,
    updated_at
) VALUES (
    now(),
    coalesce($1::jsonb, '{}'::jsonb),
    $2::text,
    coalesce($3::timestamptz, NULL),
    coalesce($4::timestamptz, now())
) ON CONFLICT (name) DO UPDATE
SET
    updated_at = coalesce($4::timestamptz, now())
RETURNING name, created_at, metadata, paused_at, updated_at
",
        )
        .bind(queue_create_or_set_updated_at_info.metadata)
        .bind(queue_create_or_set_updated_at_info.name)
        .bind(queue_create_or_set_updated_at_info.paused_at)
        .bind(queue_create_or_set_updated_at_info.updated_at)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct QueueDeleteExpiredRow {
    pub name: String,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}
pub async fn queue_delete_expired<'e, E>(
    db: E,
    updated_at_horizon: chrono::DateTime<chrono::Utc>,
    max: i64,
) -> Result<Vec<QueueDeleteExpiredRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<QueueDeleteExpiredRow> = sqlx::query_as(
            "
DELETE FROM river_queue
WHERE name IN (
    SELECT name
    FROM river_queue
    WHERE updated_at < $1::timestamptz
    ORDER BY name ASC
    LIMIT $2::bigint
)
RETURNING name, created_at, metadata, paused_at, updated_at
",
        )
        .bind(updated_at_horizon)
        .bind(max)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct QueueGetRow {
    pub name: String,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}
pub async fn queue_get<'e, E>(db: E, name: String) -> Result<QueueGetRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: QueueGetRow = sqlx::query_as(
            "
SELECT name, created_at, metadata, paused_at, updated_at
FROM river_queue
WHERE name = $1::text
",
        )
        .bind(name)
        .fetch_one(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct QueueListRow {
    pub name: String,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}
pub async fn queue_list<'e, E>(
    db: E,
    limit_count: i32,
) -> Result<Vec<QueueListRow>, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    let rec: Vec<QueueListRow> = sqlx::query_as(
            "
SELECT name, created_at, metadata, paused_at, updated_at
FROM river_queue
ORDER BY name ASC
LIMIT $1::integer
",
        )
        .bind(limit_count)
        .fetch_all(db)
        .await?;
    Ok(rec)
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct QueuePauseRow {
    pub name: String,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}
pub async fn queue_pause<'e, E>(
    db: E,
    name: String,
) -> Result<QueuePauseRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    sqlx::query(
            "
WITH queue_to_update AS (
    SELECT name, paused_at
    FROM river_queue
    WHERE CASE WHEN $1::text = '*' THEN true ELSE name = $1 END
    FOR UPDATE
),
updated_queue AS (
    UPDATE river_queue
    SET
        paused_at = now(),
        updated_at = now()
    FROM queue_to_update
    WHERE river_queue.name = queue_to_update.name
        AND river_queue.paused_at IS NULL
    RETURNING river_queue.name, river_queue.created_at, river_queue.metadata, river_queue.paused_at, river_queue.updated_at
)
SELECT name, created_at, metadata, paused_at, updated_at
FROM river_queue
WHERE name = $1
    AND name NOT IN (SELECT name FROM updated_queue)
UNION
SELECT name, created_at, metadata, paused_at, updated_at
FROM updated_queue
",
        )
        .bind(name)
        .execute(db)
        .await?;
    Err(sqlx::Error::TypeNotFound {
        type_name: String::from(":execresult"),
    })
}
#[derive(Debug, Clone, sqlx::FromRow)]
pub struct QueueResumeRow {
    pub name: String,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub metadata: sqlx::types::Json<serde_json::Value>,
    pub paused_at: Option<chrono::DateTime<chrono::Utc>>,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}
pub async fn queue_resume<'e, E>(
    db: E,
    name: String,
) -> Result<QueueResumeRow, sqlx::Error>
where
    E: sqlx::Executor<'e, Database = sqlx::Postgres>,
{
    sqlx::query(
            "
WITH queue_to_update AS (
    SELECT name
    FROM river_queue
    WHERE CASE WHEN $1::text = '*' THEN true ELSE river_queue.name = $1::text END
    FOR UPDATE
),
updated_queue AS (
    UPDATE river_queue
    SET
        paused_at = NULL,
        updated_at = now()
    FROM queue_to_update
    WHERE river_queue.name = queue_to_update.name
    RETURNING river_queue.name, river_queue.created_at, river_queue.metadata, river_queue.paused_at, river_queue.updated_at
)
SELECT name, created_at, metadata, paused_at, updated_at
FROM river_queue
WHERE name = $1
    AND name NOT IN (SELECT name FROM updated_queue)
UNION
SELECT name, created_at, metadata, paused_at, updated_at
FROM updated_queue
",
        )
        .bind(name)
        .execute(db)
        .await?;
    Err(sqlx::Error::TypeNotFound {
        type_name: String::from(":execresult"),
    })
}
